# NN from scratch 


## DONE: 
* Define num of layers : 4
* Num of neuron: 512 256 128 64
* Epochs : 200
* Batch size : 128
* Input layer : 3072
* Implement activation function (RELU, Sigmoid, Softmax)
* Build a loss function : CES 

## TODO: 
* Build a mlp classifier  
  * build a layer
* Implement forward propagation
* Implement backward propagation 
* Implement Adam, SGD
* Implement dropout and batch normalization
* Implement the train
* Implement the predict
* Implement the accuracy
